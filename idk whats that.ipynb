{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e47fb368",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MrSwi\\anaconda3\\envs\\projects\\lib\\site-packages\\pinecone\\index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "# importing  important libraries\n",
    "import streamlit as st\n",
    "import cohere\n",
    "import pinecone\n",
    "import openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8444f3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  storing api keys both cohere and pinecone\n",
    "pinecone_api_key = ''\n",
    "cohere_api_key = \n",
    "\n",
    "# initializing cohere and pinecone\n",
    "co = cohere.Client(cohere_api_key)\n",
    "\n",
    "index_name = 'tafsir'\n",
    "pinecone.init(pinecone_api_key, environment='us-west1-gcp')\n",
    "\n",
    "\n",
    "# connect to index\n",
    "index = pinecone.Index(index_name)\n",
    "\n",
    "# defining the limit of the context\n",
    "limit = 1600\n",
    "\n",
    "def retrieve(query):\n",
    "    xq = co.embed(\n",
    "        texts=[query],\n",
    "        model='multilingual-22-12',\n",
    "        truncate='NONE'\n",
    "    ).embeddings\n",
    "    # search pinecone index for context passage with the answer\n",
    "    xc = index.query(xq, top_k=3, include_metadata=True)\n",
    "    contexts = [\n",
    "        x['metadata']['text'] for x in xc['matches']\n",
    "    ]\n",
    "\n",
    "    # build our prompt with the retrieved contexts included\n",
    "    prompt_start = (\n",
    "        \"Answer the Query based on the contexts, if it's not in the contexts say 'I don't know the answer'. \\n\\n\"+\n",
    "        \"Context:\\n\"\n",
    "    )\n",
    "    prompt_end = (\n",
    "        f\"\\n\\nQuery: {query}\\nAnswer in the language of Query, if Query is in English Answer in English. Please provide reference Quran verses.\"\n",
    "    )\n",
    "    # append contexts until hitting limit\n",
    "    for i in range(1, len(contexts)):\n",
    "        if len(\"\\n\\n---\\n\\n\".join(contexts[:i])) >= limit:\n",
    "            prompt = (\n",
    "                prompt_start +\n",
    "                \"\\n\\n---\\n\\n\".join(contexts[:i-1]) +\n",
    "                prompt_end\n",
    "            )\n",
    "            break\n",
    "        elif i == len(contexts)-1:\n",
    "            prompt = (\n",
    "                prompt_start +\n",
    "                \"\\n\\n---\\n\\n\".join(contexts) +\n",
    "                prompt_end\n",
    "            )\n",
    "    return prompt\n",
    "\n",
    "# st.markdown(\"### if nothing is written in text box the above mentioned text is by default recommended to you\")\n",
    "    \n",
    "\n",
    "# st.spinner(\"Searching for the answer\")\n",
    "# query_with_contexts = retrieve(query)\n",
    "# query_with_contexts \n",
    "\n",
    "\n",
    "\n",
    "# get API key from top-right dropdown on OpenAI website\n",
    "openai.api_key = st.secrets[openai_API_key]\n",
    "\n",
    "\n",
    "def complete(prompt):\n",
    "    # query text-davinci-003\n",
    "    res = openai.Completion.create(\n",
    "        engine='text-davinci-003',\n",
    "        prompt=prompt,\n",
    "        temperature=0,\n",
    "        max_tokens=1000,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stop=None\n",
    "    )\n",
    "    return res['choices'][0]['text'].strip()\n",
    "\n",
    "# complete(query_with_contexts)\n",
    "# st.text(results)\n",
    "\n",
    "# st.markdown(results)\n",
    "\n",
    "results = ''\n",
    "\n",
    "with st.form(\"my_form\"):\n",
    "    query = st.text_area(\":green[Enter Your :question: Question] :point_left:\", \n",
    "                help= \"Ask question on any topic in the Holy Quran\",\n",
    "                height=100,\n",
    "                placeholder=\"Ask question on any topic in the Holy Quran\")\n",
    "\n",
    "    submitted = st.form_submit_button(\"Submit\")\n",
    "    if submitted:\n",
    "        query_with_contexts = retrieve(query)\n",
    "        results = complete(query_with_contexts)\n",
    "\n",
    "st.write(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd683f14",
   "metadata": {},
   "outputs": [
    {
     "ename": "ApiKeyError",
     "evalue": "\"You haven't specified an Api-Key.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mApiKeyError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 21\u001b[0m, in \u001b[0;36mretrieve\u001b[1;34m(query)\u001b[0m\n\u001b[0;32m     15\u001b[0m xq \u001b[38;5;241m=\u001b[39m co\u001b[38;5;241m.\u001b[39membed(\n\u001b[0;32m     16\u001b[0m     texts\u001b[38;5;241m=\u001b[39m[query],\n\u001b[0;32m     17\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmultilingual-22-12\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     18\u001b[0m     truncate\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNONE\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     19\u001b[0m )\u001b[38;5;241m.\u001b[39membeddings\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# search pinecone index for context passage with the answer\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m xc \u001b[38;5;241m=\u001b[39m \u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m contexts \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     23\u001b[0m     x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m xc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatches\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     24\u001b[0m ]\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# build our prompt with the retrieved contexts included\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\projects\\lib\\site-packages\\pinecone\\core\\utils\\error_handling.py:15\u001b[0m, in \u001b[0;36mvalidate_and_convert_errors.<locals>.inner_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner_func\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 15\u001b[0m     \u001b[43mConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# raises exceptions in case of invalid config\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\projects\\lib\\site-packages\\pinecone\\config.py:56\u001b[0m, in \u001b[0;36m_CONFIG.validate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mapi_key:  \u001b[38;5;66;03m# None or empty string invalid\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ApiKeyError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou haven\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt specified an Api-Key.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mApiKeyError\u001b[0m: \"You haven't specified an Api-Key.\""
     ]
    }
   ],
   "source": [
    "retrieve(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce05226",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# st.markdown(\"### if nothing is written in text box the above mentioned text is by default recommended to you\")\n",
    "    \n",
    "\n",
    "# st.spinner(\"Searching for the answer\")\n",
    "# query_with_contexts = retrieve(query)\n",
    "# query_with_contexts \n",
    "\n",
    "\n",
    "\n",
    "# get API key from top-right dropdown on OpenAI website\n",
    "openai.api_key = st.secrets[openai_API_key]\n",
    "\n",
    "\n",
    "def complete(prompt):\n",
    "    # query text-davinci-003\n",
    "    res = openai.Completion.create(\n",
    "        engine='text-davinci-003',\n",
    "        prompt=prompt,\n",
    "        temperature=0,\n",
    "        max_tokens=1000,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stop=None\n",
    "    )\n",
    "    return res['choices'][0]['text'].strip()\n",
    "\n",
    "# complete(query_with_contexts)\n",
    "# st.text(results)\n",
    "\n",
    "# st.markdown(results)\n",
    "\n",
    "results = ''\n",
    "\n",
    "with st.form(\"my_form\"):\n",
    "    query = st.text_area(\":green[Enter Your :question: Question] :point_left:\", \n",
    "                help= \"Ask question on any topic in the Holy Quran\",\n",
    "                height=100,\n",
    "                placeholder=\"Ask question on any topic in the Holy Quran\")\n",
    "\n",
    "    submitted = st.form_submit_button(\"Submit\")\n",
    "    if submitted:\n",
    "        query_with_contexts = retrieve(query)\n",
    "        results = complete(query_with_contexts)\n",
    "\n",
    "st.write(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projects",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
